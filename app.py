import streamlit as st
import pandas as pd
import joblib
import os

# Chemin du dossier courant (o√π se trouve app.py)
current_dir = os.path.dirname(os.path.abspath(__file__))

# Chargement du mod√®le et du scaler
model_path = os.path.join(current_dir, "extra_trees_model.pkl")
scaler_path = os.path.join(current_dir, "scaler.pkl")
model = joblib.load(model_path)
scaler = joblib.load(scaler_path)

st.title("D√©tection d'attaques IoT")
st.write("Application de classification des types d'attaques r√©seau IoT")

# Upload du fichier CSV
uploaded_file = st.file_uploader("Importer un fichier CSV", type=["csv"])

if uploaded_file is not None:
    df_new = pd.read_csv(uploaded_file)
    
    st.subheader("Aper√ßu des donn√©es")
    st.dataframe(df_new.head())
    
    # Supprimer colonne inutile si pr√©sente
    if "Unnamed: 0" in df_new.columns:
        df_new = df_new.drop(columns=["Unnamed: 0"])
    
    try:
        # R√©cup√©rer les colonnes attendues par le scaler
        colonnes_attendues = scaler.feature_names_in_
        
        # V√©rifier si toutes les colonnes n√©cessaires sont pr√©sentes
        colonnes_manquantes = set(colonnes_attendues) - set(df_new.columns)
        colonnes_en_trop = set(df_new.columns) - set(colonnes_attendues)
        
        if colonnes_manquantes:
            st.error(f" Colonnes manquantes dans le fichier : {list(colonnes_manquantes)}")
            st.stop()
        
        if colonnes_en_trop:
            st.warning(f" Colonnes ignor√©es (non utilis√©es par le mod√®le) : {list(colonnes_en_trop)}")
        
        # S√©lectionner et r√©organiser les colonnes dans le bon ordre
        df_for_prediction = df_new[colonnes_attendues]
        
        # Normalisation
        df_scaled = scaler.transform(df_for_prediction)
        
        # Pr√©diction
        predictions = model.predict(df_scaled)
        
        # Ajouter les pr√©dictions au DataFrame original (avec toutes les colonnes)
        df_new["Prediction_Attack_type"] = predictions
        
        st.subheader("R√©sultats de la pr√©diction")
        st.dataframe(df_new.head())
        
        # Afficher la distribution des pr√©dictions
        st.subheader("Distribution des types d'attaques d√©tect√©es")
        prediction_counts = pd.Series(predictions).value_counts()
        st.bar_chart(prediction_counts)
        
        # T√©l√©chargement
        csv = df_new.to_csv(index=False).encode("utf-8")
        st.download_button(
            "üì• T√©l√©charger les r√©sultats",
            csv,
            "predictions.csv",
            "text/csv",
            key="download-csv"
        )
        
        st.success(f" Pr√©diction r√©ussie pour {len(df_new)} enregistrements")
        
    except AttributeError:
        # Si le scaler n'a pas feature_names_in_ (ancienne version sklearn)
        st.error(" Le scaler ne contient pas les noms de colonnes. Veuillez r√©entra√Æner le mod√®le avec une version r√©cente de scikit-learn.")
        st.info("Tentative de pr√©diction avec les colonnes dans l'ordre actuel...")
        
        df_scaled = scaler.transform(df_new)
        predictions = model.predict(df_scaled)
        df_new["Prediction_Attack_type"] = predictions
        
        st.subheader("R√©sultats de la pr√©diction")
        st.dataframe(df_new.head())
        
        csv = df_new.to_csv(index=False).encode("utf-8")
        st.download_button(
            "üì• T√©l√©charger les r√©sultats",
            csv,
            "predictions.csv",
            "text/csv"
        )
        
    except Exception as e:
        st.error(f" Erreur lors de la pr√©diction : {str(e)}")
        st.write("Informations de d√©bogage :")
        st.write(f"- Nombre de colonnes dans le fichier : {len(df_new.columns)}")
        st.write(f"- Colonnes du fichier : {df_new.columns.tolist()}")  
